## V0 Roadmap - Fall'23

- [x] Draft implementation with CGO llama.cpp backend
- [x] Simple REST API to allow text generation
- [x] Inference with Apple Silicon GPU using Metal framework
- [x] Parallel inference both with CPU and GPU
- [x] Support both AMD64  and ARM64 platforms
- [x] CUDA support and fast inference with Nvidia cards
- [x] Retain dialog history by Session ID parameter
- [x] Support moderm GGUF V3 model format
- [x] Inference for most popular LLM architectures
- [x] Janus Sampling for better non-English text generation

## V1 Roadmap - Winter'23

- [x] Rebrand project: LLaMAZoo => Large Model Collider
- [x] Is it 2023, 30th of November? First birthday of ChatGPT! **Celebrate ...**
- [x] **... then release Collider V1** after half a year of honing it :)

## V2 Roadmap - Spring'24

- [x] Full LLaMA v2 support
- [x] Freeze JSON / YAML config format for Native API

## V3 Roadmap - Summer'24

- [x] Rebrand project again :) **Collider => Booster**
- [x] Complete LLaMA v3 support
- [x] OpenAI API Chat Completion compatible endpoints
- [x] Ollama compatible endpoints
- [x] Interactive mode for chatting from command line
- [x] Update Janus Sampling for LLaMA-3
- [ ] Broader integration with Ollama ecosystem
- [ ] Smarter context shrinking when reaching its limits chatting with model
- [ ] Embedded web UI with no external dependencies
- [ ] Allow native Windows support
- [ ] Prebuilt binaries for all platforms
- [ ] Support LLaVA multi-modal models inference
- [ ] Better code test coverage
- [ ] Perplexity computation useful for benchmarking
